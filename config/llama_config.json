{
    "model_type": "llama3_1B", 
    "pos_encode": "rope", 
    "tokenizer_path": "./tokenizer/tokenizer.model", 

    "use_compile": false,
    "load_weights": null,
    "ckpt_path": "", 

    "lora": false, 
    "lora_alpha": 1,
    "lora_rank": 1, 

    "parallel_dims": {
        "dp": 1, 
        "tp": 1, 
        "pp": 1
    }, 
    "dp": {
        "dp_shard" : false
    }, 
    "tp": {
        "parallel_loss": false
    }, 
    "pp": {
        "pipeline_parallel_schedule": "gpipe"
    }, 

    "params": {
        "dim": 256, 
        "n_layers": 6, 
        "n_heads": 4, 
        "n_kv_heads": 2, 
        "vocab_size": 128256, 
        "multiple_of": 1024, 
        "ffn_dim_multiplier": 1.3, 
        "norm_eps": 1e-5, 
        "rope_theta": 500000.0, 
        "max_batch_size": 4, 
        "max_seq_len": 1024, 
        "long_term_memory": false
    }
}
